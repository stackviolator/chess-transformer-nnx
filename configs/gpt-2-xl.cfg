transformer:
  debug: false
  train: true
  d_model: 1600
  d_head: 64
  d_mlp: 6400
  n_layers: 48
  n_heads: 25
  ctx_len: 128
  stddev: 0.02
  ln_eps: 1e-5
  dropout_rate: 0.1
  seed: 0
  pad_token_id: null
  ckpt_dir: "trained_models/gpt-2-xl"